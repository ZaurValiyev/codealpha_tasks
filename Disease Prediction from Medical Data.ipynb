{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7abfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, confusion_matrix, \n",
    "                           classification_report, roc_curve, auc)\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ecb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading and Preparation\n",
    "def load_medical_data():\n",
    "    \"\"\"Load and prepare medical dataset\"\"\"\n",
    "    # Note: In practice, you would use your actual medical dataset\n",
    "    # This example uses the Heart Disease UCI dataset from Kaggle as a stand-in\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "    column_names = [\n",
    "        'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "        'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        data = pd.read_csv(url, names=column_names, na_values='?')\n",
    "    except:\n",
    "        print(\"Unable to fetch online data, loading local copy if available\")\n",
    "        # Fallback to local file if online fetch fails\n",
    "        data = pd.read_csv('heart_disease.csv', names=column_names, na_values='?')\n",
    "    \n",
    "    # Convert target to binary (0 = no disease, 1 = disease)\n",
    "    data['target'] = data['target'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458ff8ef",
   "metadata": {},
   "source": [
    "Replace the load_medical_data() function with your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocessing Setup\n",
    "def get_medical_preprocessor():\n",
    "    \"\"\"Create preprocessing pipeline for medical data\"\"\"\n",
    "    # Identify feature types\n",
    "    categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "    numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "    \n",
    "    # Numeric preprocessing\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "    \n",
    "    # Categorical preprocessing\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    return preprocessor, categorical_features, numerical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35c143",
   "metadata": {},
   "source": [
    "Adjust feature lists in get_medical_preprocessor() for your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Model Training with Random Forest\n",
    "def train_medical_model(X_train, y_train, preprocessor):\n",
    "    \"\"\"Train and tune a Random Forest classifier for medical prediction\"\"\"\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    # Reduced parameter grid for faster execution\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5],\n",
    "        'classifier__min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Evaluation\n",
    "def evaluate_medical_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate model performance with medical metrics\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall (Sensitivity)': recall_score(y_test, y_pred),\n",
    "        'Specificity': recall_score(y_test, y_pred, pos_label=0),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_proba)\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nModel Performance Metrics:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix with labels\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['No Disease', 'Disease'],\n",
    "                yticklabels=['No Disease', 'Disease'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba1e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Feature Importance Analysis\n",
    "def plot_medical_feature_importance(model, preprocessor, numerical_features, categorical_features):\n",
    "    \"\"\"Plot medical feature importances\"\"\"\n",
    "    # Get feature names\n",
    "    categorical_transformer = preprocessor.named_transformers_['cat']\n",
    "    if hasattr(categorical_transformer, 'named_steps'):\n",
    "        onehot = categorical_transformer.named_steps['onehot']\n",
    "        cat_feature_names = onehot.get_feature_names_out(categorical_features)\n",
    "    else:\n",
    "        cat_feature_names = categorical_transformer.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    all_feature_names = numerical_features + list(cat_feature_names)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.named_steps['classifier'].feature_importances_\n",
    "    \n",
    "    # Create DataFrame and sort\n",
    "    feature_importances = pd.DataFrame({'feature': all_feature_names, 'importance': importances})\n",
    "    feature_importances = feature_importances.sort_values('importance', ascending=False).head(15)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importances['feature'], feature_importances['importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Top 15 Predictive Features')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Deployment Example\n",
    "def save_and_predict_medical(model):\n",
    "    \"\"\"Save model and demonstrate prediction with medical data\"\"\"\n",
    "    # Save the model\n",
    "    joblib.dump(model, 'disease_prediction_model.pkl')\n",
    "    print(\"\\nModel saved as 'disease_prediction_model.pkl'\")\n",
    "    \n",
    "    # Create sample patient data\n",
    "    sample_patient = {\n",
    "        'age': 58,\n",
    "        'sex': 1,          # 1 = male, 0 = female\n",
    "        'cp': 3,           # chest pain type (0-3)\n",
    "        'trestbps': 140,   # resting blood pressure\n",
    "        'chol': 289,       # serum cholesterol\n",
    "        'fbs': 0,          # fasting blood sugar > 120 mg/dl\n",
    "        'restecg': 1,      # resting electrocardiographic results\n",
    "        'thalach': 140,    # maximum heart rate achieved\n",
    "        'exang': 0,        # exercise induced angina\n",
    "        'oldpeak': 3.5,    # ST depression induced by exercise\n",
    "        'slope': 2,        # slope of peak exercise ST segment\n",
    "        'ca': 1,           # number of major vessels colored by flourosopy\n",
    "        'thal': 3          # thalassemia (3 = normal, 6 = fixed defect, 7 = reversible defect)\n",
    "    }\n",
    "    \n",
    "    sample_df = pd.DataFrame([sample_patient])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(sample_df)\n",
    "    probability = model.predict_proba(sample_df)[:, 1]\n",
    "    \n",
    "    print(\"\\nSample Patient Prediction:\")\n",
    "    print(f\"Predicted Disease Status: {'Disease Present' if prediction[0] == 1 else 'No Disease'}\")\n",
    "    print(f\"Probability of Disease: {probability[0]:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0758dbcb",
   "metadata": {},
   "source": [
    "You can adjust samples according to the testing you want to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8868d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Execution\n",
    "def main():\n",
    "    print(\"1. Loading medical data...\")\n",
    "    data = load_medical_data()\n",
    "    \n",
    "    # Basic data exploration\n",
    "    print(\"\\nData Overview:\")\n",
    "    print(f\"Total records: {len(data)}\")\n",
    "    print(f\"Disease prevalence: {data['target'].mean():.1%}\")\n",
    "    print(\"\\nFirst 5 records:\")\n",
    "    print(data.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "    # Handle missing values (simple imputation for this example)\n",
    "    data.fillna(data.median(numeric_only=True), inplace=True)\n",
    "    data.fillna(data.mode().iloc[0], inplace=True)\n",
    "    \n",
    "    X = data.drop('target', axis=1)\n",
    "    y = data['target']\n",
    "    \n",
    "    print(\"\\n2. Splitting data into train/test sets...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    print(\"\\n3. Setting up medical data preprocessing...\")\n",
    "    preprocessor, categorical_features, numerical_features = get_medical_preprocessor()\n",
    "    \n",
    "    print(\"\\n4. Training Random Forest model...\")\n",
    "    grid_search = train_medical_model(X_train, y_train, preprocessor)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    print(\"\\n5. Evaluating model performance...\")\n",
    "    metrics = evaluate_medical_model(best_model, X_test, y_test)\n",
    "    \n",
    "    print(\"\\n6. Analyzing important medical features...\")\n",
    "    plot_medical_feature_importance(best_model, preprocessor, numerical_features, categorical_features)\n",
    "    \n",
    "    print(\"\\n7. Saving model and testing prediction...\")\n",
    "    save_and_predict_medical(best_model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
